<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Speech Transcription</title>
    <style>
        /* Same CSS styles as before */
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }

        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        button {
            padding: 12px 24px;
            font-size: 16px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.3s;
        }

        #startBtn {
            background-color: #4CAF50;
            color: white;
        }

        #startBtn:hover {
            background-color: #45a049;
        }

        #stopBtn {
            background-color: #f44336;
            color: white;
        }

        #stopBtn:hover {
            background-color: #da190b;
        }

        #startBtn:disabled,
        #stopBtn:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }

        .transcription-box {
            border: 1px solid #ddd;
            padding: 20px;
            border-radius: 4px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            background-color: #fff;
            margin-top: 20px;
        }

        .status {
            text-align: center;
            margin-top: 10px;
            color: #666;
        }

        #transcriptionText {
            white-space: pre-wrap;
            line-height: 1.5;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Real-time Speech Transcription</h1>

        <div class="controls">
            <button id="startBtn">Start Recording</button>
            <button id="stopBtn" disabled>Stop Recording</button>
        </div>

        <div class="transcription-box">
            <div id="transcriptionText"></div>
        </div>

        <div class="status" id="status"></div>
    </div>

    <script>
        let mediaRecorder;
        let socket;
        let audioContext;
        let isRecording = false;
        let stream;
        let isStoppingInProgress = false;

        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const transcriptionText = document.getElementById('transcriptionText');
        const statusElement = document.getElementById('status');

        function updateStatus(message) {
            statusElement.textContent = message;
        }

        function clearTranscription() {
            transcriptionText.textContent = '';
        }

        function cleanupResources() {
            if (socket && socket.readyState === WebSocket.OPEN) {
                socket.close();
            }

            if (audioContext) {
                audioContext.close();
            }

            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
        }

        async function initAudio() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000
                    }
                });

                // Updated WebSocket URL to use current protocol (ws/wss)
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                socket = new WebSocket(`${protocol}//${window.location.host}/audio-stream`);

                audioContext = new AudioContext({
                    sampleRate: 16000,
                });

                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);

                source.connect(processor);
                processor.connect(audioContext.destination);

                processor.onaudioprocess = (e) => {
                    if (isRecording && socket.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        const pcmData = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            pcmData[i] = Math.min(1, Math.max(-1, inputData[i])) * 0x7FFF;
                        }
                        socket.send(pcmData.buffer);
                    }
                };

                socket.onopen = () => {
                    updateStatus('WebSocket connected');
                };

                socket.onclose = () => {
                    updateStatus('WebSocket connection closed');
                    startBtn.disabled = false;
                    if (isRecording) {
                        stopRecording('websocket-close');
                    }
                };

                socket.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    updateStatus('WebSocket error occurred');
                    if (isRecording) {
                        stopRecording('websocket-error');
                    }
                };

                return stream;
            } catch (error) {
                console.error('Error accessing microphone:', error);
                updateStatus('Error accessing microphone');
                throw error;
            }
        }

        async function startRecording() {
            if (isStoppingInProgress) {
                return;
            }

            try {
                clearTranscription();
                updateStatus('Initializing microphone...');

                await initAudio();
                isRecording = true;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                updateStatus('Recording in progress...');

                socket.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        if (data.transcribed_text) {
                            transcriptionText.textContent = data.transcribed_text;
                            transcriptionText.parentElement.scrollTop =
                                transcriptionText.parentElement.scrollHeight;
                        }
                    } catch (e) {
                        console.error('Error parsing WebSocket message:', e);
                    }
                };

            } catch (error) {
                console.error('Error:', error);
                updateStatus('Error starting recording');
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        }

        async function stopRecording(source = 'button') {
            if (isStoppingInProgress) {
                return;
            }

            try {
                isStoppingInProgress = true;
                stopBtn.disabled = true;
                updateStatus('Processing final text... Please wait...');

                await new Promise(resolve => setTimeout(resolve, 2000));

                isRecording = false;

                cleanupResources();
                updateStatus('Recording stopped');
                startBtn.disabled = false;

            } catch (error) {
                console.error('Error:', error);
                updateStatus('Error stopping recording');
            } finally {
                isStoppingInProgress = false;
            }
        }

        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', () => stopRecording('button'));

        window.addEventListener('beforeunload', async () => {
            if (isRecording) {
                await stopRecording('unload');
            }
        });
    </script>
</body>

</html>